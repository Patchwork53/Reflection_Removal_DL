{"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install gdown -q","metadata":{"execution":{"iopub.status.busy":"2023-05-28T13:57:55.171188Z","iopub.execute_input":"2023-05-28T13:57:55.171649Z","iopub.status.idle":"2023-05-28T13:58:08.737679Z","shell.execute_reply.started":"2023-05-28T13:57:55.171620Z","shell.execute_reply":"2023-05-28T13:58:08.736543Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!gdown https://drive.google.com/uc?id=1-h9Uno7UB8MPWmYpcWQzMy0ukWkEZ62F\n!gdown https://drive.google.com/uc?id=1O5TF1LJMTr03FSUWO5_4Abh-Irl3U0DA","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uSVdoP9cnWjS","outputId":"c2678100-2c69-4e21-8014-925a420df974","execution":{"iopub.status.busy":"2023-05-28T13:58:08.741439Z","iopub.execute_input":"2023-05-28T13:58:08.741805Z","iopub.status.idle":"2023-05-28T13:59:56.109876Z","shell.execute_reply.started":"2023-05-28T13:58:08.741774Z","shell.execute_reply":"2023-05-28T13:59:56.108731Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Downloading...\nFrom (uriginal): https://drive.google.com/uc?id=1-h9Uno7UB8MPWmYpcWQzMy0ukWkEZ62F\nFrom (redirected): https://drive.google.com/uc?id=1-h9Uno7UB8MPWmYpcWQzMy0ukWkEZ62F&confirm=t&uuid=9594ae9e-0fda-4812-890f-1f480110f7ae\nTo: /kaggle/working/transmission_layer.tar.gz\n100%|████████████████████████████████████████| 688M/688M [00:45<00:00, 15.1MB/s]\nDownloading...\nFrom (uriginal): https://drive.google.com/uc?id=1O5TF1LJMTr03FSUWO5_4Abh-Irl3U0DA\nFrom (redirected): https://drive.google.com/uc?id=1O5TF1LJMTr03FSUWO5_4Abh-Irl3U0DA&confirm=t&uuid=dcee1697-2553-4d4e-b216-030bdff2434f\nTo: /kaggle/working/reflection_layer.tar.gz\n100%|████████████████████████████████████████| 690M/690M [00:52<00:00, 13.2MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"%%capture\n!tar -xvzf /kaggle/working/transmission_layer.tar.gz\n!tar -xvzf /kaggle/working/reflection_layer.tar.gz","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZlJL5HDnsSzg","outputId":"300b11df-3187-44a5-ba74-642eb7a917fc","execution":{"iopub.status.busy":"2023-05-28T13:59:56.111855Z","iopub.execute_input":"2023-05-28T13:59:56.112237Z","iopub.status.idle":"2023-05-28T14:00:11.158409Z","shell.execute_reply.started":"2023-05-28T13:59:56.112199Z","shell.execute_reply":"2023-05-28T14:00:11.157175Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport scipy.stats as st\nk_sz=np.linspace(1,5,80) # for synthetic images\n","metadata":{"id":"zxqqwshVscGk","execution":{"iopub.status.busy":"2023-05-28T14:00:11.161455Z","iopub.execute_input":"2023-05-28T14:00:11.161770Z","iopub.status.idle":"2023-05-28T14:00:11.833978Z","shell.execute_reply.started":"2023-05-28T14:00:11.161743Z","shell.execute_reply":"2023-05-28T14:00:11.832770Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"\n\n# functions for synthesizing images with reflection (details in the paper)\ndef gkern(kernlen=100, nsig=1):\n    \"\"\"Returns a 2D Gaussian kernel array.\"\"\"\n    interval = (2*nsig+1.)/(kernlen)\n    x = np.linspace(-nsig-interval/2., nsig+interval/2., kernlen+1)\n    kern1d = np.diff(st.norm.cdf(x))\n    kernel_raw = np.sqrt(np.outer(kern1d, kern1d))\n    kernel = kernel_raw/kernel_raw.sum()\n    kernel = kernel/kernel.max()\n    return kernel\n\n\ng_mask=gkern(560,3)\ng_mask=np.dstack((g_mask,g_mask,g_mask))\n\ndef syn_data(t,r,sigma):\n    t=np.power(t,2.2)\n    r=np.power(r,2.2)\n    \n    sz=int(2*np.ceil(2*sigma)+1)\n    r_blur=cv2.GaussianBlur(r,(sz,sz),sigma,sigma,0)\n    blend=r_blur+t\n    \n    att=1.08+np.random.random()/10.0\n    \n    for i in range(3):\n        maski=blend[:,:,i]>1\n        mean_i=max(1.,np.sum(blend[:,:,i]*maski)/(maski.sum()+1e-6))\n        r_blur[:,:,i]=r_blur[:,:,i]-(mean_i-1)*att\n    r_blur[r_blur>=1]=1\n    r_blur[r_blur<=0]=0\n\n    h,w=r_blur.shape[0:2]\n    neww=np.random.randint(0, 560-w-10)\n    newh=np.random.randint(0, 560-h-10)\n    alpha1=g_mask[newh:newh+h,neww:neww+w,:]\n    alpha2 = 1-np.random.random()/5.0;\n    r_blur_mask=np.multiply(r_blur,alpha1)\n    blend=r_blur_mask+t*alpha2\n    \n    t=np.power(t,1/2.2)\n    r_blur_mask=np.power(r_blur_mask,1/2.2)\n    blend=np.power(blend,1/2.2)\n    blend[blend>=1]=1\n    blend[blend<=0]=0\n\n    return t,r_blur_mask,blend\n","metadata":{"id":"OHNYRzyqrT4d","execution":{"iopub.status.busy":"2023-05-28T14:00:11.839894Z","iopub.execute_input":"2023-05-28T14:00:11.843300Z","iopub.status.idle":"2023-05-28T14:00:11.884874Z","shell.execute_reply.started":"2023-05-28T14:00:11.843261Z","shell.execute_reply":"2023-05-28T14:00:11.882687Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Image Preprocessing. Set new_dim here.","metadata":{}},{"cell_type":"code","source":"import cv2\nnew_dim=256\n\nimg = cv2.imread(\"reflection_layer/4059.jpg\")\nwidth, height,_ = img.shape\nmin_dim = min(width, height)\nimg = img[:min_dim, :min_dim]\nimg = cv2.resize(img, (new_dim, new_dim), cv2.INTER_CUBIC)\n\nr = np.float32(img)/255.0\n             \n","metadata":{"id":"at_IOZ1yseHM","execution":{"iopub.status.busy":"2023-05-28T14:00:11.890915Z","iopub.execute_input":"2023-05-28T14:00:11.892677Z","iopub.status.idle":"2023-05-28T14:00:12.065986Z","shell.execute_reply.started":"2023-05-28T14:00:11.892636Z","shell.execute_reply":"2023-05-28T14:00:12.065022Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"\nimg = cv2.imread(\"transmission_layer/4059.jpg\")\nwidth, height,_ = img.shape\nmin_dim = min(width, height)\nimg = img[:min_dim, :min_dim]\nimg = cv2.resize(img, (new_dim, new_dim), cv2.INTER_CUBIC)\n\nt = np.float32(img)/255.0\n             ","metadata":{"id":"PCwLI4G_uCwC","execution":{"iopub.status.busy":"2023-05-28T14:00:12.067215Z","iopub.execute_input":"2023-05-28T14:00:12.067564Z","iopub.status.idle":"2023-05-28T14:00:12.081142Z","shell.execute_reply.started":"2023-05-28T14:00:12.067532Z","shell.execute_reply":"2023-05-28T14:00:12.080185Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"sigma=k_sz[np.random.randint(0, len(k_sz))]\n_t, blur_mask, blend = syn_data(t,r,sigma)\nblend.shape, _t.shape, blur_mask.shape","metadata":{"id":"SLNm7zrJvNFO","execution":{"iopub.status.busy":"2023-05-28T14:00:12.082369Z","iopub.execute_input":"2023-05-28T14:00:12.082796Z","iopub.status.idle":"2023-05-28T14:00:12.122514Z","shell.execute_reply.started":"2023-05-28T14:00:12.082764Z","shell.execute_reply":"2023-05-28T14:00:12.121454Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"((256, 256, 3), (256, 256, 3), (256, 256, 3))"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport PIL\nimport os\nimport torch\nimport pandas as pd\nfrom skimage import io, transform\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, utils\n\n# Ignore warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n# Device configuration\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nplt.ion()   # interactive mode\n# torch.set_default_dtype(torch.float32)","metadata":{"id":"oE8yD9VswRO6","execution":{"iopub.status.busy":"2023-05-28T14:00:12.123843Z","iopub.execute_input":"2023-05-28T14:00:12.124279Z","iopub.status.idle":"2023-05-28T14:00:15.318465Z","shell.execute_reply.started":"2023-05-28T14:00:12.124245Z","shell.execute_reply":"2023-05-28T14:00:15.317439Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"<contextlib.ExitStack at 0x7da5fc9d6620>"},"metadata":{}}]},{"cell_type":"code","source":"device","metadata":{"execution":{"iopub.status.busy":"2023-05-28T14:00:15.322964Z","iopub.execute_input":"2023-05-28T14:00:15.323466Z","iopub.status.idle":"2023-05-28T14:00:15.329533Z","shell.execute_reply.started":"2023-05-28T14:00:15.323439Z","shell.execute_reply":"2023-05-28T14:00:15.328621Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Cropping and Resizing Reflection Images","metadata":{}},{"cell_type":"code","source":"!mkdir /kaggle/working/r_images","metadata":{"id":"JgMFJwh6ywaE","execution":{"iopub.status.busy":"2023-05-28T14:00:15.330830Z","iopub.execute_input":"2023-05-28T14:00:15.331691Z","iopub.status.idle":"2023-05-28T14:00:16.541109Z","shell.execute_reply.started":"2023-05-28T14:00:15.331658Z","shell.execute_reply":"2023-05-28T14:00:16.539427Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"import os\nfrom tqdm import tqdm\n\npath = \"/kaggle/working/reflection_layer\"\nsave_to = \"/kaggle/working/r_images\"\nfor file in tqdm(os.listdir(path)):\n    img = cv2.imread(path+\"/\"+file) \n    width, height,_ = img.shape\n    min_dim = min(width, height)\n    img = img[:min_dim, :min_dim]\n    img = cv2.resize(img, (new_dim, new_dim))\n    cv2.imwrite(save_to+\"/\"+file, img)\n  ","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pSJSjhhqxved","outputId":"c7e77632-fbbf-4aad-b223-94e2b4faf310","execution":{"iopub.status.busy":"2023-05-28T14:00:16.543278Z","iopub.execute_input":"2023-05-28T14:00:16.543698Z","iopub.status.idle":"2023-05-28T14:01:40.047317Z","shell.execute_reply.started":"2023-05-28T14:00:16.543658Z","shell.execute_reply":"2023-05-28T14:01:40.046266Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"100%|██████████| 13700/13700 [01:23<00:00, 164.12it/s]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Cropping and Resizing Target/Transmission Images","metadata":{}},{"cell_type":"code","source":"!mkdir /kaggle/working/t_images","metadata":{"id":"LU57Xa7Q3Gor","execution":{"iopub.status.busy":"2023-05-28T14:01:40.048955Z","iopub.execute_input":"2023-05-28T14:01:40.049330Z","iopub.status.idle":"2023-05-28T14:01:41.071099Z","shell.execute_reply.started":"2023-05-28T14:01:40.049297Z","shell.execute_reply":"2023-05-28T14:01:41.069587Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"import os\nfrom tqdm import tqdm\n\npath = \"/kaggle/working/transmission_layer\"\nsave_to = \"/kaggle/working/t_images\"\nfor file in tqdm(os.listdir(path)):\n    img = cv2.imread(path+\"/\"+file) \n    width, height,_ = img.shape\n    min_dim = min(width, height)\n    img = img[:min_dim, :min_dim]\n    img = cv2.resize(img, (new_dim, new_dim))\n    cv2.imwrite(save_to+\"/\"+file, img)\n  ","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GOT35zWRzYMs","outputId":"836c14e6-9d7e-4ec7-c31e-281a85bcbc17","execution":{"iopub.status.busy":"2023-05-28T14:01:41.073082Z","iopub.execute_input":"2023-05-28T14:01:41.073449Z","iopub.status.idle":"2023-05-28T14:03:05.695939Z","shell.execute_reply.started":"2023-05-28T14:01:41.073411Z","shell.execute_reply":"2023-05-28T14:03:05.694985Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"100%|██████████| 13749/13749 [01:24<00:00, 162.51it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\n\nlt = [int(x.split(\".\")[0]) for x in os.listdir(\"/kaggle/working/t_images\")]\nlt.sort()\nlt[-1]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"725ouq4q0Fx9","outputId":"e56a50c8-2bd1-4d11-c8fe-7ebe87e243eb","execution":{"iopub.status.busy":"2023-05-28T14:03:05.697450Z","iopub.execute_input":"2023-05-28T14:03:05.698315Z","iopub.status.idle":"2023-05-28T14:03:05.721381Z","shell.execute_reply.started":"2023-05-28T14:03:05.698281Z","shell.execute_reply":"2023-05-28T14:03:05.720368Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"15000"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Filling in missing images by copying a random image","metadata":{}},{"cell_type":"code","source":"import os\nimport shutil\n\n# Specify the folder path where the images are located\nfolder_path = \"/kaggle/working/t_images\"\n\n# Specify the file extension of the images\nfile_extension = \".jpg\"\n\n# Specify the range of image numbers\nstart_number = 1\nend_number = 15000\n\n# Iterate over the range of image numbers\nfor i in range(start_number, end_number + 1):\n    # Generate the filename for the current image\n    filename = str(i) + file_extension\n    \n    # Check if the image file exists\n    if not os.path.isfile(os.path.join(folder_path, filename)):\n        # Search for an existing image to copy and rename\n        for j in range(i + 1, end_number + 1):\n            existing_filename = str(j) + file_extension\n            if os.path.isfile(os.path.join(folder_path, existing_filename)):\n                # Copy and rename the existing image to fill the missing image\n                shutil.copy2(os.path.join(folder_path, existing_filename),\n                             os.path.join(folder_path, filename))\n#                 print(f\"Filled missing image: {filename} with {existing_filename}\")\n                break\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TQuOr4N6z_uc","outputId":"b913f637-4fae-43ff-baae-72d221f5ec2f","execution":{"iopub.status.busy":"2023-05-28T14:03:05.722917Z","iopub.execute_input":"2023-05-28T14:03:05.723269Z","iopub.status.idle":"2023-05-28T14:03:06.016356Z","shell.execute_reply.started":"2023-05-28T14:03:05.723237Z","shell.execute_reply":"2023-05-28T14:03:06.015408Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"import os\nimport shutil\n\n# Specify the folder path where the images are located\nfolder_path = \"/kaggle/working/r_images\"\n\n# Specify the file extension of the images\nfile_extension = \".jpg\"\n\n# Specify the range of image numbers\nstart_number = 1\nend_number = 15000\n\n# Iterate over the range of image numbers\nfor i in range(start_number, end_number + 1):\n    # Generate the filename for the current image\n    filename = str(i) + file_extension\n    \n    # Check if the image file exists\n    if not os.path.isfile(os.path.join(folder_path, filename)):\n        # Search for an existing image to copy and rename\n        for j in range(i + 1, end_number + 1):\n            existing_filename = str(j) + file_extension\n            if os.path.isfile(os.path.join(folder_path, existing_filename)):\n                # Copy and rename the existing image to fill the missing image\n                shutil.copy2(os.path.join(folder_path, existing_filename),\n                             os.path.join(folder_path, filename))\n#                 print(f\"Filled missing image: {filename} with {existing_filename}\")\n                break\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iZos_Th40iRF","outputId":"dc0dbd42-29a1-493a-f638-759c47143ac1","execution":{"iopub.status.busy":"2023-05-28T14:03:06.017801Z","iopub.execute_input":"2023-05-28T14:03:06.018230Z","iopub.status.idle":"2023-05-28T14:03:06.318215Z","shell.execute_reply.started":"2023-05-28T14:03:06.018197Z","shell.execute_reply":"2023-05-28T14:03:06.317270Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# !cp /kaggle/working/transmission_layer2/35.jpg /kaggle/working/transmission_layer2/34.jpg\n# !cp /kaggle/working/blended2/35.jpg /kaggle/working/blended2/34.jpg","metadata":{"id":"73K53fx73J3i","execution":{"iopub.status.busy":"2023-05-28T14:03:06.319680Z","iopub.execute_input":"2023-05-28T14:03:06.320048Z","iopub.status.idle":"2023-05-28T14:03:06.326351Z","shell.execute_reply.started":"2023-05-28T14:03:06.320015Z","shell.execute_reply":"2023-05-28T14:03:06.325436Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"### Statically creating the dataset i.e. target_image + reflection = input_image\n\nTakes time. Consider saving it as a kaggle dataset","metadata":{}},{"cell_type":"code","source":"!mkdir /kaggle/working/i_images","metadata":{"id":"qMgZ7NRGzhkR","execution":{"iopub.status.busy":"2023-05-28T14:03:06.327741Z","iopub.execute_input":"2023-05-28T14:03:06.328286Z","iopub.status.idle":"2023-05-28T14:03:07.264534Z","shell.execute_reply.started":"2023-05-28T14:03:06.328231Z","shell.execute_reply":"2023-05-28T14:03:07.263267Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"for t_image in tqdm(os.listdir(\"/kaggle/working/t_images\")):\n    t = cv2.imread(\"/kaggle/working/t_images/\"+t_image)\n    t = t.astype(np.float32)/255.0\n    r = cv2.imread(\"/kaggle/working/r_images/\"+t_image)\n    r = r.astype(np.float32)/255.0\n\n    sigma=k_sz[np.random.randint(0, len(k_sz))]\n    _,_,input_image = syn_data(t, r, sigma)\n\n    i = (input_image*255).astype(np.uint8)\n    cv2.imwrite(\"/kaggle/working/i_images/\"+t_image, i)\n  \n\n\n\n    \n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kx3xE5f3cnaX","outputId":"4507d3cb-ac0f-4c5b-f409-e49a31dbe429","execution":{"iopub.status.busy":"2023-05-28T14:03:07.266505Z","iopub.execute_input":"2023-05-28T14:03:07.266869Z","iopub.status.idle":"2023-05-28T14:08:52.154234Z","shell.execute_reply.started":"2023-05-28T14:03:07.266832Z","shell.execute_reply":"2023-05-28T14:08:52.153142Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"100%|██████████| 15000/15000 [05:44<00:00, 43.50it/s]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## UNET","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\n# U-Net architecture\nclass UNet(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(UNet, self).__init__()\n\n        # Contracting path\n        self.conv1 = self.double_conv(in_channels, 64)\n        self.pool1 = nn.MaxPool2d(2)\n        self.conv2 = self.double_conv(64, 128)\n        self.pool2 = nn.MaxPool2d(2)\n        self.conv3 = self.double_conv(128, 256)\n        self.pool3 = nn.MaxPool2d(2)\n        self.conv4 = self.double_conv(256, 512)\n        self.pool4 = nn.MaxPool2d(2)\n        self.conv5 = self.double_conv(512, 1024)\n\n        # Expanding path\n        self.upconv1 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n        self.conv6 = self.double_conv(1024, 512)\n        self.upconv2 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n        self.conv7 = self.double_conv(512, 256)\n        self.upconv3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n        self.conv8 = self.double_conv(256, 128)\n        self.upconv4 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n        self.conv9 = self.double_conv(128, 64)\n\n        # Output layer\n        self.outconv = nn.Conv2d(64, out_channels, kernel_size=1)\n\n    def double_conv(self, in_channels, out_channels):\n        return nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self, x):\n        # Contracting path\n        c1 = self.conv1(x)\n        p1 = self.pool1(c1)\n        c2 = self.conv2(p1)\n        p2 = self.pool2(c2)\n        c3 = self.conv3(p2)\n        p3 = self.pool3(c3)\n        c4 = self.conv4(p3)\n        p4 = self.pool4(c4)\n        c5 = self.conv5(p4)\n\n        # Expanding path\n        up1 = self.upconv1(c5)\n        merge1 = torch.cat([up1, c4], dim=1)\n        c6 = self.conv6(merge1)\n        up2 = self.upconv2(c6)\n        merge2 = torch.cat([up2, c3], dim=1)\n        c7 = self.conv7(merge2)\n        up3 = self.upconv3(c7)\n        merge3 = torch.cat([up3, c2], dim=1)\n        c8 = self.conv8(merge3)\n        up4 = self.upconv4(c8)\n        merge4 = torch.cat([up4, c1], dim=1)\n        c9 = self.conv9(merge4)\n\n        # Output layer\n        output = self.outconv(c9)\n        return output\n","metadata":{"id":"n90xFGZyz9iy","execution":{"iopub.status.busy":"2023-05-28T14:08:52.156045Z","iopub.execute_input":"2023-05-28T14:08:52.156712Z","iopub.status.idle":"2023-05-28T14:08:52.173463Z","shell.execute_reply.started":"2023-05-28T14:08:52.156677Z","shell.execute_reply":"2023-05-28T14:08:52.172397Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"3f87m8uK27qK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dataset for Static Input Images.\n\nHas a cache mechanism (default disabled) which may or maynot improve speed. Cache doesn't work with >5000 dataset","metadata":{}},{"cell_type":"code","source":"\nimport random\n\nclass ReflectDataset(Dataset):\n  \n    def __init__(self, input_dir, reflect_dir, target_dir, dataset_len, offset, do_cache=False):\n        self.target_dir = target_dir\n        self.reflect_dir = reflect_dir\n        self.input_dir = input_dir\n        self.dataset_len = dataset_len\n        self.offset = offset\n        \n        self.do_cache = do_cache\n        if self.do_cache:\n            self.cache = [None]*dataset_len\n\n    def __len__(self):\n        return self.dataset_len\n\n    def __getitem__(self, idx):\n        \n        if self.do_cache and self.cache[idx]:\n            return self.cache[idx]\n    \n        \n        img_name = self.reflect_dir+\"/\"+str( random.randint(1, 15000) )+\".jpg\"\n    \n        img_name = self.target_dir+\"/\"+str(self.offset+idx+1)+\".jpg\"\n        target_image = cv2.imread(img_name)\n        target_image = target_image.astype(np.float32)/255.0\n\n        img_name = self.input_dir+\"/\"+str(self.offset+idx+1)+\".jpg\"\n        input_image = cv2.imread(img_name)\n        input_image = input_image.astype(np.float32)/255.0\n        input_image = torch.from_numpy(input_image).to(device)   \n        input_image = input_image.permute(2, 0, 1)\n\n        \n        target_image = torch.from_numpy(target_image).to(device)        \n        target_image = target_image.permute(2,0,1)\n\n       \n        if self.do_cache:      \n            self.cache[idx]=(input_image,target_image)\n\n        return input_image,target_image","metadata":{"id":"J3HauWAJz-LY","execution":{"iopub.status.busy":"2023-05-28T14:08:52.176962Z","iopub.execute_input":"2023-05-28T14:08:52.177308Z","iopub.status.idle":"2023-05-28T14:08:52.189186Z","shell.execute_reply.started":"2023-05-28T14:08:52.177274Z","shell.execute_reply":"2023-05-28T14:08:52.188287Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"### Class that generates on the fly. Quite slow.","metadata":{}},{"cell_type":"code","source":"\nimport random\n\nclass ReflectDataset_OTF(Dataset):\n  \n    def __init__(self, input_dir, reflect_dir, target_dir, dataset_len, offset):\n        self.target_dir = target_dir\n        self.reflect_dir = reflect_dir\n        self.input_dir = input_dir\n        self.dataset_len = dataset_len\n        self.offset = offset\n\n    def __len__(self):\n        return self.dataset_len\n\n    def __getitem__(self, idx):\n     \n        img_name = self.reflect_dir+\"/\"+str( random.randint(1, 15000) )+\".jpg\"\n\n        reflection = cv2.imread(img_name) \n        reflection = reflection.astype(np.float32)/255.0\n\n        \n        img_name = self.target_dir+\"/\"+str(self.offset+idx+1)+\".jpg\"\n        target_image = cv2.imread(img_name)\n        target_image = target_image.astype(np.float32)/255.0\n\n        sigma=k_sz[np.random.randint(0, len(k_sz))]\n        _,_,input_image = syn_data(target_image, reflection, sigma)\n        input_image = torch.from_numpy(input_image.astype(np.float32)).to(device)\n\n      \n        input_image = input_image.permute(2, 0, 1)\n\n        \n        target_image = torch.from_numpy(target_image).to(device)        \n        target_image = target_image.permute(2,0,1)\n\n    \n        return input_image,target_image","metadata":{"execution":{"iopub.status.busy":"2023-05-28T14:08:52.190603Z","iopub.execute_input":"2023-05-28T14:08:52.190956Z","iopub.status.idle":"2023-05-28T14:08:52.201533Z","shell.execute_reply.started":"2023-05-28T14:08:52.190925Z","shell.execute_reply":"2023-05-28T14:08:52.200423Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"n = len(os.listdir(\"/kaggle/working/t_images\"))\nprint(n)","metadata":{"execution":{"iopub.status.busy":"2023-05-28T14:08:52.203392Z","iopub.execute_input":"2023-05-28T14:08:52.203793Z","iopub.status.idle":"2023-05-28T14:08:52.221001Z","shell.execute_reply.started":"2023-05-28T14:08:52.203763Z","shell.execute_reply":"2023-05-28T14:08:52.220039Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"15000\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Reduce dataset here.","metadata":{"id":"ZvI36QN9iriy"}},{"cell_type":"code","source":"n=1000","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r0blcuSSdcA2","outputId":"c36afc90-45f7-49a7-da51-bc765c9502ed","execution":{"iopub.status.busy":"2023-05-28T14:08:52.222349Z","iopub.execute_input":"2023-05-28T14:08:52.222753Z","iopub.status.idle":"2023-05-28T14:08:52.227290Z","shell.execute_reply.started":"2023-05-28T14:08:52.222721Z","shell.execute_reply":"2023-05-28T14:08:52.226251Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"## Change from Static to Dynamic Here","metadata":{}},{"cell_type":"code","source":"\n# split = 0.25\n# offset = int(split*n)\n# train_ds = ReflectDataset_OTF(\"/kaggle/working/i_images\",\"/kaggle/working/r_images\",\"/kaggle/working/t_images\",offset,0)\n# test_ds = ReflectDataset_OTF(\"/kaggle/working/i_images\",\"/kaggle/working/r_images\",\"/kaggle/working/t_images\",n-offset,offset)","metadata":{"execution":{"iopub.status.busy":"2023-05-28T14:08:52.229030Z","iopub.execute_input":"2023-05-28T14:08:52.229364Z","iopub.status.idle":"2023-05-28T14:08:52.236746Z","shell.execute_reply.started":"2023-05-28T14:08:52.229333Z","shell.execute_reply":"2023-05-28T14:08:52.235904Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"\nsplit = 0.25\noffset = int(split*n)\ntrain_ds = ReflectDataset(\"/kaggle/working/i_images\",\"/kaggle/working/r_images\",\"/kaggle/working/t_images\",offset,0)\ntest_ds = ReflectDataset(\"/kaggle/working/i_images\",\"/kaggle/working/r_images\",\"/kaggle/working/t_images\",n-offset,offset)","metadata":{"id":"akZCIsk92ACx","execution":{"iopub.status.busy":"2023-05-28T14:08:52.238035Z","iopub.execute_input":"2023-05-28T14:08:52.238510Z","iopub.status.idle":"2023-05-28T14:08:52.244981Z","shell.execute_reply.started":"2023-05-28T14:08:52.238461Z","shell.execute_reply":"2023-05-28T14:08:52.243983Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"batch_size = 8\ntrain_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size,shuffle=True)\n\ntest_loader = torch.utils.data.DataLoader(test_ds, batch_size=2*batch_size,shuffle=False)\n","metadata":{"id":"gRzMGnr326g9","execution":{"iopub.status.busy":"2023-05-28T14:08:52.251663Z","iopub.execute_input":"2023-05-28T14:08:52.251917Z","iopub.status.idle":"2023-05-28T14:08:52.257278Z","shell.execute_reply.started":"2023-05-28T14:08:52.251894Z","shell.execute_reply":"2023-05-28T14:08:52.256331Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"for i, batch in enumerate(train_loader):\n    print(batch[0].shape)\n    print(batch[1].shape)\n    break","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2WyF2Iuy44eV","outputId":"d85fa508-a075-4831-d705-1d91422cd66a","execution":{"iopub.status.busy":"2023-05-28T14:08:52.258764Z","iopub.execute_input":"2023-05-28T14:08:52.259424Z","iopub.status.idle":"2023-05-28T14:08:55.009207Z","shell.execute_reply.started":"2023-05-28T14:08:52.259392Z","shell.execute_reply":"2023-05-28T14:08:55.008129Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"torch.Size([8, 3, 256, 256])\ntorch.Size([8, 3, 256, 256])\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.cuda.empty_cache()\n\n# Example usage\nin_channels = 3  # Number of input channels\nout_channels = 3 # Number of output channels\nmodel = UNet(in_channels, out_channels).to(device)\n\nfor i, batch in enumerate(train_loader):\n    input_images = batch[0]\n    target_images = batch[1]\n    \n    predictions = model(input_images)\n    \n    print(predictions.shape)\n    break\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p7NgXGNl4w47","outputId":"b704958e-c4e1-4030-fc74-40995126ee88","execution":{"iopub.status.busy":"2023-05-28T14:08:55.010946Z","iopub.execute_input":"2023-05-28T14:08:55.011626Z","iopub.status.idle":"2023-05-28T14:08:59.413167Z","shell.execute_reply.started":"2023-05-28T14:08:55.011591Z","shell.execute_reply":"2023-05-28T14:08:59.411309Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"torch.Size([8, 3, 256, 256])\n","output_type":"stream"}]},{"cell_type":"code","source":"train_num_batches = len(train_ds)/(batch_size)\ntest_num_batches = len(test_ds)/(2*batch_size)","metadata":{"id":"uEq1UhL6BdBI","execution":{"iopub.status.busy":"2023-05-28T14:08:59.414448Z","iopub.execute_input":"2023-05-28T14:08:59.414901Z","iopub.status.idle":"2023-05-28T14:08:59.420130Z","shell.execute_reply.started":"2023-05-28T14:08:59.414865Z","shell.execute_reply":"2023-05-28T14:08:59.419124Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"\ntorch.cuda.empty_cache()\n# model = Generator(in_channels,out_features).to(device)\n# model.load_state_dict(torch.load('/kaggle/working/best_weights.pth', map_location = device))\n\n# model.load_state_dict(torch.load('best_weights.pth'))\nnum_epochs = 50\n\n# Example usage\nin_channels = 3  # Number of input channels\nout_channels = 3 # Number of output channels\nmodel = UNet(in_channels, out_channels).to(device)\n\ncriterion = nn.MSELoss()\nlearning_rate = 0.0003\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n\n# scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=learning_rate, steps_per_epoch=len(train_ds), epochs=num_epochs)\n","metadata":{"id":"ZVSX7nuBAuup","execution":{"iopub.status.busy":"2023-05-28T14:08:59.421568Z","iopub.execute_input":"2023-05-28T14:08:59.422241Z","iopub.status.idle":"2023-05-28T14:08:59.982906Z","shell.execute_reply.started":"2023-05-28T14:08:59.422209Z","shell.execute_reply":"2023-05-28T14:08:59.981675Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"\nmin_test_loss = 1000000\nfor epoch in range(num_epochs):\n    epoch_train_loss = 0\n    epoch_test_loss = 0\n    epoch_rand_loss = 0\n    \n    model.train()\n    for i, batch in enumerate(train_loader):\n      \n        images = batch[0]\n        targets = batch[1]\n\n        # Forward pass\n        predictions = model(images)\n        train_loss = criterion(predictions, targets)\n        epoch_train_loss += train_loss\n\n        # Backward and optimize\n        optimizer.zero_grad()\n        train_loss.backward()\n        optimizer.step()\n       \n    model.eval()\n  \n    with torch.no_grad():\n\n        for i, test_batch in enumerate(test_loader):\n            images = test_batch[0]\n            targets = test_batch[1]\n            test_predictions = model(images)\n            test_loss = criterion(test_predictions, targets)\n            epoch_test_loss += test_loss \n        \n\n    epoch_test_loss  = epoch_test_loss/test_num_batches\n    epoch_train_loss = epoch_train_loss/train_num_batches\n   \n    if min_test_loss > epoch_test_loss:\n        min_test_loss = epoch_test_loss\n        print(\"saving on epoch\",epoch)\n        torch.save(model.state_dict(), './model1.pth')\n    \n#     print(f'rand loss: {epoch_rand_loss:.4f}')\n    print (f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {epoch_train_loss:.4f} Test Loss: {epoch_test_loss:.4f}, Ratio: {epoch_test_loss/epoch_train_loss:.4f}')\n    \n\nprint('Finished Training')\nPATH = './model2.pth'\ntorch.save(model.state_dict(), PATH)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":432},"id":"FjVQqpmaBfw7","outputId":"291b96a6-4129-459e-d8e6-9b98cb5149fc","execution":{"iopub.status.busy":"2023-05-28T14:08:59.984340Z","iopub.execute_input":"2023-05-28T14:08:59.984789Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"saving on epoch 0\nEpoch [1/50], Train Loss: 0.0896 Test Loss: 0.0337, Ratio: 0.3766\nsaving on epoch 1\nEpoch [2/50], Train Loss: 0.0317 Test Loss: 0.0268, Ratio: 0.8467\nsaving on epoch 2\nEpoch [3/50], Train Loss: 0.0264 Test Loss: 0.0211, Ratio: 0.8009\nEpoch [4/50], Train Loss: 0.0256 Test Loss: 0.0235, Ratio: 0.9189\nsaving on epoch 4\nEpoch [5/50], Train Loss: 0.0234 Test Loss: 0.0209, Ratio: 0.8925\nsaving on epoch 5\nEpoch [6/50], Train Loss: 0.0231 Test Loss: 0.0203, Ratio: 0.8777\nsaving on epoch 6\nEpoch [7/50], Train Loss: 0.0219 Test Loss: 0.0194, Ratio: 0.8848\nEpoch [8/50], Train Loss: 0.0215 Test Loss: 0.0200, Ratio: 0.9293\nEpoch [9/50], Train Loss: 0.0212 Test Loss: 0.0196, Ratio: 0.9252\nsaving on epoch 9\nEpoch [10/50], Train Loss: 0.0209 Test Loss: 0.0186, Ratio: 0.8890\nEpoch [11/50], Train Loss: 0.0215 Test Loss: 0.0186, Ratio: 0.8674\nEpoch [12/50], Train Loss: 0.0211 Test Loss: 0.0195, Ratio: 0.9225\nEpoch [13/50], Train Loss: 0.0207 Test Loss: 0.0198, Ratio: 0.9570\nEpoch [14/50], Train Loss: 0.0208 Test Loss: 0.0191, Ratio: 0.9143\nsaving on epoch 14\nEpoch [15/50], Train Loss: 0.0204 Test Loss: 0.0181, Ratio: 0.8897\nEpoch [16/50], Train Loss: 0.0207 Test Loss: 0.0192, Ratio: 0.9288\nEpoch [17/50], Train Loss: 0.0212 Test Loss: 0.0185, Ratio: 0.8687\nEpoch [18/50], Train Loss: 0.0207 Test Loss: 0.0191, Ratio: 0.9215\nEpoch [19/50], Train Loss: 0.0204 Test Loss: 0.0186, Ratio: 0.9108\nEpoch [20/50], Train Loss: 0.0207 Test Loss: 0.0185, Ratio: 0.8911\n","output_type":"stream"}]},{"cell_type":"code","source":"\nmodel.load_state_dict(torch.load('/kaggle/working/model1.pth', map_location = device))\nmodel.eval()","metadata":{"id":"d3diRKX96jFW","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nimport torchvision.transforms.functional as F\n\n\ndef imshow(imgs):\n    if not isinstance(imgs, list):\n        imgs = [imgs]\n    fig, axs = plt.subplots(ncols=len(imgs), squeeze=False)\n    for i, img in enumerate(imgs):\n        img = img.detach()\n        img = F.to_pil_image(img)\n        axs[0, i].imshow(np.asarray(img))\n        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n        \n# imshow(torchvision.utils.make_grid(list( train_ds[100] )))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nwith torch.no_grad():\n\n    for i, test_batch in enumerate(test_loader):\n        images = test_batch[0]\n        targets = test_batch[1]\n        test_predictions = model(images)\n\n\n        all_images = []\n        for image,image2,image3 in zip(images,targets,test_predictions):\n            gen_img=image\n#             image = (image.permute(1,2,0).cpu().numpy()*255).astype(np.uint8)\n            all_images.append(image)\n\n       \n#             image2 = (image2.permute(1,2,0).cpu().numpy()*255).astype(np.uint8)\n            all_images.append(image2)\n\n          \n#             image3 = (image3.permute(1,2,0).cpu().numpy()*255).astype(np.uint8)\n            all_images.append(image3)\n            \n        idx = 1\n        imshow(torchvision.utils.make_grid([images[idx],targets[idx],test_predictions[idx]]))\n        break","metadata":{"id":"P2iz8EIxHKnu","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"olOKrDh9lZZs"},"execution_count":null,"outputs":[]}]}